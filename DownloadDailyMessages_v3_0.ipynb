{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wahesh/threatInspect/blob/main/DownloadDailyMessages_v3_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most of the code for downloading the messages comes from TelegramScrap https://colab.research.google.com/drive/1lzn_XomUI9uCMLkGjQf6-2JnkKazgevh?usp=sharing#scrollTo=NEn8Clkqe0dh"
      ],
      "metadata": {
        "id": "joyV3Gk_Hu9W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZsx37l0m_SJ"
      },
      "outputs": [],
      "source": [
        "# @title **1. [ Required ] Set up your credentials once** { display-mode: \"form\" }\n",
        "\n",
        "# @markdown Here, you need to input your credentials: `username`, `phone`, `api_id`, and `api_hash`. Your `api_id` and `api_hash` can only be generated from [Telegram's app creation page](https://my.telegram.org/apps). If you want to get the English translations, you also need the Gemini API key. Once your credentials are set up, you won’t need to update them again. Just click “Run” to proceed.\n",
        "\n",
        "# Install the Telethon library for Telegram API interactions\n",
        "!pip install -q telethon\n",
        "\n",
        "# Initial imports\n",
        "from datetime import datetime, timezone\n",
        "import pandas as pd\n",
        "import time\n",
        "import json\n",
        "import re\n",
        "\n",
        "from tenacity import (\n",
        "    retry,\n",
        "    stop_after_attempt,\n",
        "    wait_random_exponential,\n",
        ")\n",
        "# Telegram imports\n",
        "from telethon.sync import TelegramClient\n",
        "\n",
        "# Google Colab imports\n",
        "from google.colab import files\n",
        "\n",
        "#Gemini AI imports\n",
        "from google.api_core import retry\n",
        "from google.generativeai.types import RequestOptions\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "#imports for formatting Excel\n",
        "from openpyxl.worksheet.datavalidation import DataValidation\n",
        "from openpyxl.utils.dataframe import dataframe_to_rows\n",
        "from openpyxl import Workbook\n",
        "from openpyxl.styles import  Border, Side, PatternFill, Alignment\n",
        "\n",
        "# Setup / change only the first time you use it\n",
        "# @markdown **1.1.** Your Telegram account username (just 'abc123', not '@'):\n",
        "username = 'none' # @param {type:\"string\"}\n",
        "# @markdown **1.2.** Your Telegram account phone number (ex: '+9011999999999'):\n",
        "phone = '+90111111111' # @param {type:\"string\"}\n",
        "# @markdown **1.3.** Telegram API ID, it can be only generated from https://my.telegram.org/apps:\n",
        "api_id = '11111' # @param {type:\"string\"}\n",
        "# @markdown **1.4.** Telegram API hash, also from https://my.telegram.org/apps:\n",
        "api_hash = '1a1a1a1a1aa1a1a1a1a1a1a1a1a1aa1a1a1a1a' # @param {type:\"string\"}\n",
        "# @markdown **1.5** Gemini API key, from Google AI studio https://ai.google.dev/gemini-api/docs/api-key. If you do not want to translate the messages automatically, you can leave this field with the default value. **In such case remember to select \"no\" in point 2.4 below!**:\n",
        "gemini_key = '1a1a1a1a1aa1a1a1a1a1a1a1a1a1aa1a1a1a1a' # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title **2. [ Required ] Adjust every time you want to use it** { display-mode: \"form\" }\n",
        "\n",
        "# @markdown In this section, you will define the parameters for scraping data from Telegram channels or groups. Specify the channels you want to scrape using the format `https://t.me/ChannelName`. Do not use URLs starting with `https://web.telegram.org/`. Set the date range by defining the start and end day, month, and year. Choose an output file name for the scraped data. Decide if you want to also get English translations using Gemini AI (the program will run longer in this case).\n",
        "\n",
        "# Setup / change every time to define scraping parameters\n",
        "\n",
        "# @markdown **2.1.** Here you put the name of the channel or group that you want to scrape, e.g.: 'https://t.me/zoda_gov_ua'. **Just write the `channel names` always separated by commas (,) without spaces:**\n",
        "channels = 'https://t.me/zoda_gov_ua,https://t.me/mykolaivskaODA,https://t.me/Sumy_news_ODA,https://t.me/mykola_lukashuk,https://t.me/synegubov,https://t.me/khmelnytskaODA,https://t.me/odeskaODA,https://t.me/kozytskyy_maksym_official,https://t.me/VadymFilashkin,https://t.me/KyivCityOfficial,https://t.me/VA_Kyiv,https://t.me/poltavskaOVA,https://t.me/kirovogradskaODA,https://t.me/zhytomyrskaODA,https://t.me/mod_russia,https://t.me/kpszsu,https://t.me/Ukrenergo' # @param {type:\"string\"}\n",
        "channels = [channel.strip() for channel in channels.split(\",\")]\n",
        "\n",
        "# @markdown **2.2.** Here you can select the `time window` you would like to extract data from the listed channels:\n",
        "date_min = '2024-12-23' # @param {type:\"date\"}\n",
        "date_max = '2024-12-31' # @param {type:\"date\"}\n",
        "\n",
        "date_min = datetime.fromisoformat(date_min).replace(tzinfo=timezone.utc)\n",
        "date_max = datetime.fromisoformat(date_max).replace(tzinfo=timezone.utc)\n",
        "\n",
        "# @markdown **2.3.** Choose a `name` for the final file you want to download as output. If you want to keep the file in the default format, please leave \"default\" in the field below:\n",
        "file_name = 'default' # @param {type:\"string\"}\n",
        "if file_name==\"default\":\n",
        "  file_name= 'daily_messages'\n",
        "# @markdown **2.4.** Would you like to translate the messages to English? (the Gemini APi_key in point 1.5 must be filled out correctly in this case)\n",
        "translate_english = \"yes\"  # @param [\"yes\", \"no\"]\n",
        "\n",
        "# @markdown **2.6.** Would you like to automatically add information where possible? (if you select no, the spreadsheed will contain only downloaded messages in Ukraininan and English, remaining values will be empty)\n",
        "automatic_info = \"yes\"  # @param [\"yes\", \"no\"]\n",
        "\n",
        "# @markdown **2.7.** Choose the format of the final file you want to download.\n",
        "File = 'excel' # @param [\"excel\", \"csv\"]\n",
        "\n",
        "max_t_index = 1000000\n",
        "time_limit = 21600\n",
        "key_search = ''\n",
        "if translate_english==\"yes\":\n",
        "  genai.configure(api_key=gemini_key)"
      ],
      "metadata": {
        "id": "czjGi736oJaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #@title **3. [ Required ] Start Telegram scraping** { display-mode: \"form\" }\n",
        "\n",
        "# @markdown **Attention:** During this step, Telegram may request a verification code. Please monitor your Telegram app and input the required information promptly. Rest assured, all data entered remains secure.\n",
        "# @markdown The program will let you know when it finishes each step: scraping data, translating, and filling out automatic fields (if you have selected such options).\n",
        "# @markdown The files will then download automatically.\n",
        "\n",
        "data = []  # List to store scraped data\n",
        "t_index = 0  # Tracker for the number of messages processed\n",
        "start_time = time.time()  # Record the start time for the scraping session\n",
        "\n",
        "# Function to remove invalid XML characters from text\n",
        "def remove_unsupported_characters(text):\n",
        "    valid_xml_chars = (\n",
        "        \"[^\\u0009\\u000A\\u000D\\u0020-\\uD7FF\\uE000-\\uFFFD\"\n",
        "        \"\\U00010000-\\U0010FFFF]\"\n",
        "    )\n",
        "    cleaned_text = re.sub(valid_xml_chars, '', text)\n",
        "    return cleaned_text\n",
        "\n",
        "# Function to format time in days, hours, minutes, and seconds\n",
        "def format_time(seconds):\n",
        "    days = seconds // 86400\n",
        "    hours = (seconds % 86400) // 3600\n",
        "    minutes = (seconds % 3600) // 60\n",
        "    seconds = seconds % 60\n",
        "    return f'{int(days):02}:{int(hours):02}:{int(minutes):02}:{int(seconds):02}'\n",
        "\n",
        "# Function to print progress of the scraping process\n",
        "def print_progress(t_index, message_id, start_time, max_t_index):\n",
        "    elapsed_time = time.time() - start_time\n",
        "    current_progress = t_index / (t_index + message_id) if (t_index + message_id) <= max_t_index else t_index / max_t_index\n",
        "    percentage = current_progress * 100\n",
        "    estimated_total_time = elapsed_time / current_progress\n",
        "    remaining_time = estimated_total_time - elapsed_time\n",
        "\n",
        "    elapsed_time_str = format_time(elapsed_time)\n",
        "    remaining_time_str = format_time(remaining_time)\n",
        "\n",
        "    print(f'Progress: {percentage:.2f}% | Elapsed Time: {elapsed_time_str} | Remaining Time: {remaining_time_str}')\n",
        "\n",
        "#Function to check if the channel is one of the regional reports or other\n",
        "def is_report(channel_adress):\n",
        "  regional_reports = [\n",
        "    'https://t.me/zoda_gov_ua',\n",
        "    'https://t.me/olexandrprokudin',\n",
        "    'https://t.me/mykolaivskaODA',\n",
        "    'https://t.me/Sumy_news_ODA',\n",
        "    'https://t.me/mykola_lukashuk',\n",
        "    'https://t.me/synegubov',\n",
        "    'https://t.me/khmelnytskaODA',\n",
        "    'https://t.me/odeskaODA',\n",
        "    'https://t.me/kozytskyy_maksym_official',\n",
        "    'https://t.me/VadymFilashkin',\n",
        "    'https://t.me/KyivCityOfficial',\n",
        "    'https://t.me/VA_Kyiv',\n",
        "    'https://t.me/poltavskaOVA',\n",
        "    'https://t.me/kirovogradskaODA',\n",
        "    'https://t.me/zhytomyrskaODA']\n",
        "  if channel_adress in regional_reports:\n",
        "    return \"yes\"\n",
        "  else:\n",
        "    return \"no\"\n",
        "\n",
        "#Function to get the name of channel (have to be pre-set)\n",
        "def channel2name(channel_adress):\n",
        "  name_dict = {\n",
        "    'https://t.me/zoda_gov_ua':'Zaporizhzhia',\n",
        "    'https://t.me/olexandrprokudin':'Kherson',\n",
        "    'https://t.me/mykolaivskaODA':'Mykolaiv',\n",
        "    'https://t.me/Sumy_news_ODA':'Sumy',\n",
        "    'https://t.me/mykola_lukashuk':'Dnipropetrovsk',\n",
        "    'https://t.me/synegubov':'Kharkiv',\n",
        "    'https://t.me/khmelnytskaODA':'Khmelnytskyi',\n",
        "    'https://t.me/odeskaODA':'Odesa',\n",
        "    'https://t.me/kozytskyy_maksym_official':'Lviv',\n",
        "    'https://t.me/VadymFilashkin':'Donetsk',\n",
        "    'https://t.me/KyivCityOfficial':'Kyiv',\n",
        "    'https://t.me/VA_Kyiv':'Kyiv 2',\n",
        "    'https://t.me/poltavskaOVA':'Poltava',\n",
        "    'https://t.me/kirovogradskaODA':'Kirovohrad',\n",
        "    'https://t.me/zhytomyrskaODA':'Zhytomyr',\n",
        "    'https://t.me/mod_russia':'Russia Ministry of Defence',\n",
        "    'https://t.me/kpszsu':'Ukraine Air Defence',\n",
        "    'https://t.me/Ukrenergo':'Ukraine Energy Company'\n",
        "  }\n",
        "  if channel_adress in name_dict:\n",
        "    return name_dict[channel_adress]\n",
        "  else:\n",
        "    return \"none\"\n",
        "\n",
        "def check_area_info(source_channels):\n",
        "  #define dictionaries for regions\n",
        "  #security area dictionary\n",
        "  srm_dict = {\"unknown\":\"unknown\",\"volyn\":\"western\",\"lviv\":\"western\",\"zakarpattia\":\"western\",\"ivano-frankivsk\":\"western\",\"ternopil\":\"western\",\"rivne\":\"western\",\n",
        "               \"chernivtsy\":\"western\",\"khmelnytsky\":\"western\",\"zhytomyr\":\"western\",\"vinnytsia\":\"western\",\"kyiv\":\"western\",\"cherkasy\":\"western\",\n",
        "              \"kropyvnytskyi\":\"western\",\"poltava\":\"western\",\"west chernihiv\":\"western\",\"odesa\":\"southern\",\"mykolaiv\":\"southern\",\"kherson\":\"southern\",\n",
        "              \"sumy\":\"eastern\",\"kharkiv\":\"eastern\",\"dnipro\":\"eastern\",\"zaporizhzhia\":\"eastern\",\"donetsk\":\"eastern\",\"north chernihiv\":\"eastern\"}\n",
        "  #channel to region dictionary\n",
        "  region_dict = {\n",
        "    'https://t.me/zoda_gov_ua':'Zaporizhzhia',\n",
        "    'https://t.me/olexandrprokudin':'Kherson',\n",
        "    'https://t.me/mykolaivskaODA':'Mykolaiv',\n",
        "    'https://t.me/Sumy_news_ODA':'Sumy',\n",
        "    'https://t.me/mykola_lukashuk':'Unknown',\n",
        "    'https://t.me/synegubov':'Kharkiv',\n",
        "    'https://t.me/khmelnytskaODA':'Khmelnytsky',\n",
        "    'https://t.me/odeskaODA':'Odesa',\n",
        "    'https://t.me/kozytskyy_maksym_official':'Lviv',\n",
        "    'https://t.me/VadymFilashkin':'Donetsk',\n",
        "    'https://t.me/KyivCityOfficial':'Kyiv',\n",
        "    'https://t.me/VA_Kyiv':'Kyiv',\n",
        "    'https://t.me/poltavskaOVA':'Poltava',\n",
        "    'https://t.me/kirovogradskaODA':'Kropyvnytskyi',\n",
        "    'https://t.me/zhytomyrskaODA':'Zhytomyr',\n",
        "    'https://t.me/mod_russia':'Unknown',\n",
        "    'https://t.me/kpszsu':'Unknown',\n",
        "    'https://t.me/Ukrenergo':'Unknown'\n",
        "  }\n",
        "  #define columns for security area and region\n",
        "\n",
        "  region = [region_dict[ch] if ch in region_dict else \"unknown\" for ch in source_channels]\n",
        "  assert len(region)==len(source_channels)\n",
        "  security_area = [srm_dict[reg.lower()] if reg.lower() in srm_dict else \"unknown\" for reg in region]\n",
        "  assert len(security_area)==len(source_channels)\n",
        "  return security_area, region\n",
        "\n",
        "#function to split datetime into two df columns\n",
        "def convert_datetime(datetime_list):\n",
        "  date_list = []\n",
        "  time_list = []\n",
        "  for dt in datetime_list:\n",
        "    date, time = dt.split(\" \")\n",
        "    date_list.append(date)\n",
        "    time_list.append(time)\n",
        "  return date_list, time_list\n",
        "\n",
        "#funtion to assign target and perpetrator based on the channel name\n",
        "def assign_target_perpetrator(channel_source):\n",
        "  target_dict = {\n",
        "    'https://t.me/zoda_gov_ua':'Ukraine',\n",
        "    'https://t.me/olexandrprokudin':'Ukraine',\n",
        "    'https://t.me/mykolaivskaODA':'Ukraine',\n",
        "    'https://t.me/Sumy_news_ODA':'Ukraine',\n",
        "    'https://t.me/mykola_lukashuk':'Ukraine',\n",
        "    'https://t.me/synegubov':'Ukraine',\n",
        "    'https://t.me/khmelnytskaODA':'Ukraine',\n",
        "    'https://t.me/odeskaODA':'Ukraine',\n",
        "    'https://t.me/kozytskyy_maksym_official':'Ukraine',\n",
        "    'https://t.me/VadymFilashkin':'Ukraine',\n",
        "    'https://t.me/KyivCityOfficial':'Ukraine',\n",
        "    'https://t.me/VA_Kyiv':'Ukraine',\n",
        "    'https://t.me/poltavskaOVA':'Ukraine',\n",
        "    'https://t.me/kirovogradskaODA':'Ukraine',\n",
        "    'https://t.me/zhytomyrskaODA':'Ukraine',\n",
        "    'https://t.me/mod_russia':'Unknown',\n",
        "    'https://t.me/kpszsu':'Unknown',\n",
        "    'https://t.me/Ukrenergo':'Unknown'\n",
        "  }\n",
        "\n",
        "  perp_dict = {\n",
        "    'https://t.me/zoda_gov_ua':'Russia',\n",
        "    'https://t.me/olexandrprokudin':'Russia',\n",
        "    'https://t.me/mykolaivskaODA':'Russia',\n",
        "    'https://t.me/Sumy_news_ODA':'Russia',\n",
        "    'https://t.me/mykola_lukashuk':'Russia',\n",
        "    'https://t.me/synegubov':'Russia',\n",
        "    'https://t.me/khmelnytskaODA':'Russia',\n",
        "    'https://t.me/odeskaODA':'Russia',\n",
        "    'https://t.me/kozytskyy_maksym_official':'Russia',\n",
        "    'https://t.me/VadymFilashkin':'Russia',\n",
        "    'https://t.me/KyivCityOfficial':'Russia',\n",
        "    'https://t.me/VA_Kyiv':'Russia',\n",
        "    'https://t.me/poltavskaOVA':'Russia',\n",
        "    'https://t.me/kirovogradskaODA':'Russia',\n",
        "    'https://t.me/zhytomyrskaODA':'Russia',\n",
        "    'https://t.me/mod_russia':'Unknown',\n",
        "    'https://t.me/kpszsu':'Unknown',\n",
        "    'https://t.me/Ukrenergo':'Unknown'\n",
        "  }\n",
        "\n",
        "  target = [target_dict[ch] if ch in target_dict else \"Unknown\" for ch in channel_source]\n",
        "  perpetrator = [perp_dict[ch] if ch in target_dict else \"Unknown\" for ch in channel_source]\n",
        "  return target, perpetrator\n",
        "\n",
        "#Function to translate Ukrainian messages to English\n",
        "\n",
        "def get_gemini_translation(df_all,input_column):\n",
        "  model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "  translations = []\n",
        "  prompt = 'Translate the text to English: '\n",
        "  untranslated_list = df[input_column].tolist()\n",
        "  for i,ukr_text in enumerate(untranslated_list):\n",
        "    if i%25==0:\n",
        "      print(f'Finished translating {i} out of {len(untranslated_list)} messages')\n",
        "    completed_prompt = prompt+ukr_text\n",
        "    model_answer = model.generate_content(completed_prompt, request_options=RequestOptions(\n",
        "                                        retry=retry.Retry(\n",
        "                                            initial=10,\n",
        "                                            multiplier=2,\n",
        "                                            maximum=60,\n",
        "                                            timeout=300)))\n",
        "    translations.append(model_answer.text)\n",
        "  assert len(untranslated_list)==len(translations)\n",
        "  df[\"Text_english\"] = translations\n",
        "  return df\n",
        "\n",
        "\n",
        "# Normalize File variable to avoid issues\n",
        "File = re.sub(r'[^a-z]', '', File.lower())  # Converts to lowercase and removes non-alphabetic characters\n",
        "\n",
        "# Scraping process\n",
        "for channel in channels:\n",
        "    if t_index >= max_t_index:\n",
        "        break\n",
        "\n",
        "    if time.time() - start_time > time_limit:\n",
        "        break\n",
        "\n",
        "    loop_start_time = time.time()\n",
        "\n",
        "    try:\n",
        "        c_index = 0\n",
        "        async with TelegramClient(username, api_id, api_hash) as client:\n",
        "            async for message in client.iter_messages(channel, search=key_search):\n",
        "                try:\n",
        "                    if date_min <= message.date <= date_max:\n",
        "\n",
        "                        # Process comments of the message\n",
        "                        comments_list = []\n",
        "                        try:\n",
        "                            async for comment_message in client.iter_messages(channel, reply_to=message.id):\n",
        "                                comment_text = comment_message.text.replace(\"'\", '\"')\n",
        "\n",
        "                                comment_media = 'True' if comment_message.media else 'False'\n",
        "\n",
        "                                comment_emoji_string = ''\n",
        "                                if comment_message.reactions:\n",
        "                                    for reaction_count in comment_message.reactions.results:\n",
        "                                        emoji = reaction_count.reaction.emoticon\n",
        "                                        count = str(reaction_count.count)\n",
        "                                        comment_emoji_string += emoji + \" \" + count + \" \"\n",
        "\n",
        "                                comment_date_time = comment_message.date.strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "                                comments_list.append({\n",
        "                                    'Type': 'comment',\n",
        "                                    'Comment Group': channel,\n",
        "                                    'Comment Author ID': comment_message.sender_id,\n",
        "                                    'Comment Content': comment_text,\n",
        "                                    'Comment Date': comment_date_time,\n",
        "                                    'Comment Message ID': comment_message.id,\n",
        "                                    'Comment Author': comment_message.post_author,\n",
        "                                    'Comment Views': comment_message.views,\n",
        "                                    'Comment Reactions': comment_emoji_string,\n",
        "                                    'Comment Shares': comment_message.forwards,\n",
        "                                    'Comment Media': comment_media,\n",
        "                                    'Comment Url': f'https://t.me/{channel}/{message.id}?comment={comment_message.id}'.replace('@', ''),\n",
        "                                })\n",
        "                        except Exception as e:\n",
        "                            comments_list = []\n",
        "                            print(f'Error processing comments: {e}')\n",
        "\n",
        "                        # Process the main message\n",
        "                        media = 'True' if message.media else 'False'\n",
        "\n",
        "                        emoji_string = ''\n",
        "                        if message.reactions:\n",
        "                            for reaction_count in message.reactions.results:\n",
        "                                emoji = reaction_count.reaction.emoticon\n",
        "                                count = str(reaction_count.count)\n",
        "                                emoji_string += emoji + \" \" + count + \" \"\n",
        "\n",
        "                        date_time = message.date.strftime('%Y-%m-%d %H:%M:%S')\n",
        "                        cleaned_content = remove_unsupported_characters(message.text)\n",
        "                        cleaned_comments_list = remove_unsupported_characters(json.dumps(comments_list))\n",
        "\n",
        "                        data.append({\n",
        "                            'Group': channel,\n",
        "                            'Group_name': channel2name(channel),\n",
        "                            'Date': date_time,\n",
        "                            'Text_ukrainian': cleaned_content\n",
        "                        })\n",
        "\n",
        "                        c_index += 1\n",
        "                        t_index += 1\n",
        "\n",
        "                        # Print progress\n",
        "                        print(f'{\"-\" * 80}')\n",
        "                        print_progress(t_index, message.id, start_time, max_t_index)\n",
        "                        current_max_id = min(c_index + message.id, max_t_index)\n",
        "                        print(f'From {channel}: {c_index:05} contents of {current_max_id:05}')\n",
        "                        print(f'Id: {message.id:05} / Date: {date_time}')\n",
        "                        print(f'Total: {t_index:05} contents until now')\n",
        "                        print(f'{\"-\" * 80}\\n\\n')\n",
        "\n",
        "                        if t_index % 1000 == 0:\n",
        "                            if File == 'parquet':\n",
        "                                backup_filename = f'backup_{file_name}_until_{t_index:05}_{channel}_ID{message.id:07}.parquet'\n",
        "                                pd.DataFrame(data).to_parquet(backup_filename, index=False)\n",
        "                            elif File == 'excel':\n",
        "                                backup_filename = f'backup_{file_name}_until_{t_index:05}_{channel}_ID{message.id:07}.xlsx'\n",
        "                                pd.DataFrame(data).to_excel(backup_filename, index=False, engine='openpyxl')\n",
        "\n",
        "                        if t_index >= max_t_index:\n",
        "                            break\n",
        "\n",
        "                        if time.time() - start_time > time_limit:\n",
        "                            break\n",
        "\n",
        "                    elif message.date < date_min:\n",
        "                        break\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f'Error processing message: {e}')\n",
        "\n",
        "        print(f'\\n\\n##### {channel} was ok with {c_index:05} posts #####\\n\\n')\n",
        "\n",
        "        df = pd.DataFrame(data)\n",
        "        if File == 'parquet':\n",
        "            partial_filename = f'complete_{channel}_in_{file_name}_until_{t_index:05}.parquet'\n",
        "            df.to_parquet(partial_filename, index=False)\n",
        "        elif File == 'excel':\n",
        "            partial_filename = f'complete_{channel}_in_{file_name}_until_{t_index:05}.xlsx'\n",
        "            df.to_excel(partial_filename, index=False, engine='openpyxl')\n",
        "        # files.download(partial_filename)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f'{channel} error: {e}')\n",
        "\n",
        "    loop_end_time = time.time()\n",
        "    loop_duration = loop_end_time - loop_start_time\n",
        "\n",
        "    if loop_duration < 60:\n",
        "        time.sleep(60 - loop_duration)\n",
        "df = pd.DataFrame(data)\n",
        "df = df[df[\"Text_ukrainian\"]!='']\n",
        "print(f'\\n{\"-\" * 50}\\n#Finished scraping! #{t_index:05} posts were scraped!\\n{\"-\" * 50}\\n\\n\\n\\n')\n",
        "\n",
        "#add translations to the dataframe\n",
        "if translate_english==\"yes\":\n",
        "  df = get_gemini_translation(df,\"Text_ukrainian\")\n",
        "  print(f'\\n{\"-\" * 50}\\n#Finished translating!\\n\\n\\n\\n')\n",
        "\n",
        "#add the columns to DataFrame to make it into template\n",
        "\n",
        "if automatic_info==\"no\":\n",
        "  df[\"security_area\"] = \"none\"\n",
        "  df[\"region\"] = \"none\"\n",
        "  df[\"city/town/area\"] = \"none\"\n",
        "  df[\"date of event\"], df[\"time of event\"] = convert_datetime(df[\"Date\"].tolist())\n",
        "  df[\"source message (original)\"] = df[\"Text_ukrainian\"]\n",
        "  df[\"source message (translated)\"] = df[\"Text_english\"]\n",
        "  df[\"target group\"] = \"none\"\n",
        "  df[\"perpetrator group\"] = \"none\"\n",
        "  df[\"threat_type\"] = \"none\"\n",
        "  df[\"incident type\"] = \"none\"\n",
        "  df[\"no of IEDs, mortars, etc.\"] = \"none\"\n",
        "  df[\"analysis/comments\"] = \"none\"\n",
        "  df[\"total casualities\"] = 0\n",
        "  df[\"deaths\"] = 0\n",
        "  df[\"injuries\"] = 0\n",
        "  df[\"source channel\"] = df[\"Group\"]\n",
        "\n",
        "else:\n",
        "  df[\"security_area\"],df[\"region\"] = check_area_info(df[\"Group\"].tolist())\n",
        "  df[\"city/town/area\"] = \"none\"\n",
        "  df[\"date of event\"], df[\"time of event\"] = convert_datetime(df[\"Date\"].tolist())\n",
        "  df[\"source message (original)\"] = df[\"Text_ukrainian\"]\n",
        "  df[\"source message (translated)\"] = df[\"Text_english\"]\n",
        "  df[\"target group\"], df[\"perpetrator group\"] = assign_target_perpetrator(df[\"Group\"].tolist())\n",
        "  df[\"threat_type\"] = \"none\"\n",
        "  df[\"incident type\"] = \"none\"\n",
        "  df[\"no of IEDs, mortars, etc.\"] = \"none\"\n",
        "  df[\"analysis/comments\"] = \"none\"\n",
        "  df[\"total casualities\"] = 0\n",
        "  df[\"deaths\"] = 0\n",
        "  df[\"injuries\"] = 0\n",
        "  df[\"source channel\"] = df[\"Group\"]\n",
        "\n",
        "#sort by telegram channel and the date (oldest messages on the top)\n",
        "df = df.sort_values(['source channel','date of event','time of event'])\n",
        "\n",
        "#drop unnecessary columns\n",
        "df = df.drop('Group', axis=1)\n",
        "df = df.drop('Group_name', axis=1)\n",
        "df = df.drop('Date', axis=1)\n",
        "df = df.drop('Text_ukrainian', axis=1)\n",
        "df = df.drop('Text_english', axis=1)\n",
        "\n",
        "#format Excel file\n",
        "\n",
        "#function for border settings\n",
        "def set_border(ws, cell_range):\n",
        "    thin = Side(border_style=\"thin\", color=\"000000\")\n",
        "    for row in ws[cell_range]:\n",
        "        for cell in row:\n",
        "            cell.border = Border(top=thin, left=thin, right=thin, bottom=thin)\n",
        "\n",
        "#copy DataFrame data to an Excel spreadsheet\n",
        "wb = Workbook()\n",
        "ws = wb.active\n",
        "\n",
        "for r in dataframe_to_rows(df, index=False, header=True):\n",
        "    ws.append(r)\n",
        "\n",
        "#format first row as column titles\n",
        "ws.print_title_rows='1:1'\n",
        "ws.freeze_panes = \"A2\"\n",
        "\n",
        "fill1 = PatternFill(start_color=\"00FFFFCC\",end_color=\"00FFFFCC\",fill_type='solid')\n",
        "fill2 = PatternFill(start_color=\"00CCFFFF\",end_color=\"00CCFFFF\",fill_type='solid')\n",
        "fill3 = PatternFill(start_color=\"00CCFFCC\",end_color=\"00CCFFCC\",fill_type='solid')\n",
        "fill4 = PatternFill(start_color=\"00FFCC99\",end_color=\"00FFCC99\",fill_type='solid')\n",
        "fill5 = PatternFill(start_color=\"00FFFF99\",end_color=\"00FFFF99\",fill_type='solid')\n",
        "fill6 = PatternFill(start_color=\"009999FF\",end_color=\"009999FF\",fill_type='solid')\n",
        "\n",
        "\n",
        "ws[\"A1\"].fill = fill1\n",
        "ws[\"B1\"].fill = fill1\n",
        "ws[\"C1\"].fill = fill1\n",
        "ws[\"D1\"].fill = fill2\n",
        "ws[\"E1\"].fill = fill2\n",
        "ws[\"F1\"].fill = fill3\n",
        "ws[\"G1\"].fill = fill3\n",
        "ws[\"H1\"].fill = fill4\n",
        "ws[\"I1\"].fill = fill4\n",
        "ws[\"J1\"].fill = fill5\n",
        "ws[\"K1\"].fill = fill5\n",
        "ws[\"L1\"].fill = fill5\n",
        "ws[\"M1\"].fill = fill6\n",
        "ws[\"N1\"].fill = fill1\n",
        "ws[\"O1\"].fill = fill1\n",
        "ws[\"P1\"].fill = fill1\n",
        "ws[\"Q1\"].fill = fill2\n",
        "\n",
        "\n",
        "\n",
        "#validate security area\n",
        "sc_list = sorted([\"unknown\",\"western\",\"southern\",\"eastern\"])\n",
        "dv_sc = DataValidation(type=\"list\", formula1=f'\"{\",\".join(sc_list)}\"', showDropDown=False, allow_blank=True)\n",
        "ws.add_data_validation(dv_sc)\n",
        "dv_sc.add('A1:A1048576')\n",
        "\n",
        "#validate region\n",
        "re_list = sorted([\"Unknown\",\"Volyn\",\"Lviv\",\"Zakarpattia\",\"Ivano-frankivsk\",\"Ternopil\",\"Rivne\",\"Chernivtsy\",\"Khmelnytsky\",\"Zhytomyr\",\"Vinnytsia\",\"Kyiv\",\"Cherkasy\",\"Kropyvnytskyi\",\n",
        "           \"Poltava\",\"West Chernihiv\",\"Odesa\",\"Mykolaiv\",\"Kherson\",\"Sumy\",\"Kharkiv\",\"Dnipro\",\"Zaporizhzhia\",\"Donetsk\",\"North Chernihiv\"])\n",
        "dv_re = DataValidation(type=\"list\", formula1=f'\"{\",\".join(re_list)}\"', showDropDown=False, allow_blank=True)\n",
        "ws.add_data_validation(dv_re)\n",
        "dv_re.add('B1:B1048576')\n",
        "\n",
        "\n",
        "#validate taget and perpetrator\n",
        "tp_list = [\"Ukraine\",\"Russia\"]\n",
        "dv_tp = DataValidation(type=\"list\", formula1=f'\"{\",\".join(tp_list)}\"', showDropDown=False, allow_blank=True)\n",
        "ws.add_data_validation(dv_tp)\n",
        "dv_tp.add('H1:H1048576')\n",
        "\n",
        "\n",
        "p_list = [\"Ukraine\",\"Russia\"]\n",
        "dv_p = DataValidation(type=\"list\", formula1=f'\"{\",\".join(p_list)}\"', showDropDown=False, allow_blank=True)\n",
        "ws.add_data_validation(dv_p)\n",
        "dv_p.add('I1:I1048576')\n",
        "\n",
        "#validate the threat type\n",
        "th_list = sorted([\"Armed Conflict\", \"Terrorism\", \"Crime\", \"Civil Unrest\", \"Hazard\", \"Information\"])\n",
        "dv_th = DataValidation(type=\"list\", formula1=f'\"{\",\".join(th_list)}\"', showDropDown=False, allow_blank=True)\n",
        "ws.add_data_validation(dv_th)\n",
        "dv_th.add('J1:J1048576')\n",
        "\n",
        "\n",
        "#wrap text in cells\n",
        "for row in ws.iter_rows():\n",
        "    for cell in row:\n",
        "        cell.alignment = Alignment(horizontal='center', vertical='center',wrapText=True)\n",
        "\n",
        "#add border to header\n",
        "set_border(ws, 'A1:Q1')\n",
        "\n",
        "\n",
        "#save the Excel file\n",
        "final_filename = file_name+\".xlsx\"\n",
        "wb.save(final_filename)\n",
        "\n"
      ],
      "metadata": {
        "id": "uL2Pd6ITp-0F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}